{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":11,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Import PyTorch Modules\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import TensorDataset, DataLoader","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import the dataset\n\ntrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')\nsample_sub = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\n\n# split train data into training and validation set with sklearn\nX_train, X_val, y_train, y_val = train_test_split(train.values[:,1:], train.values[:,0], test_size=0.2)\n\n# Load and convert the dataset into tensor\ntrain_dataset = TensorDataset(torch.from_numpy(X_train.astype(np.float32)/255), torch.from_numpy(y_train))\nval_dataset = TensorDataset(torch.from_numpy(X_val.astype(np.float32)/255), torch.from_numpy(y_val))\ntest_dataset = TensorDataset(torch.from_numpy(test.values[:,:].astype(np.float32)/255))\n\n\n#DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Define the Neural_Network\nclass Neural_Net(nn.Module):\n    def __init__(self):\n        super(Neural_Net, self).__init__()\n        \n        self.input = nn.Linear(28*28, 512)\n        self.hidden=  nn.Linear(512, 256)\n        self.output = nn.Linear(256,10)\n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self, x):\n        x = x.view(-1, 28*28)\n        x = F.relu(self.dropout(self.input(x)))\n        x = F.relu(self.dropout(self.hidden(x)))\n        x = self.output(x)\n        return x\n    \nmodel = Neural_Net()\nprint(model)\n        ","execution_count":15,"outputs":[{"output_type":"stream","text":"Neural_Net(\n  (input): Linear(in_features=784, out_features=512, bias=True)\n  (hidden): Linear(in_features=512, out_features=256, bias=True)\n  (output): Linear(in_features=256, out_features=10, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define Criterion and Optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the Model\n\nepochs = 30\nfor epoch in range(epochs):\n    train_loss = 0.0\n    for data, target in train_loader:\n        # Zero the gradient\n        optimizer.zero_grad()\n        # Forward Propagation\n        output = model(data)\n        # Calculate the Loss\n        loss = criterion(output, target)\n        # Back Propagation\n        loss.backward()\n        # Update weights using the optimizer\n        optimizer.step()\n        # Calculate the Cummulated Loss\n        train_loss += loss.item()*data.size(0)\n        \n    train_loss = train_loss/len(train_loader.dataset)\n    print(f\"Epoch: {epoch}, Train Loss: {train_loss}\")","execution_count":23,"outputs":[{"output_type":"stream","text":"Epoch: 0, Train Loss: 0.02908407331793569\nEpoch: 1, Train Loss: 0.026168279388941645\nEpoch: 2, Train Loss: 0.02383734275491969\nEpoch: 3, Train Loss: 0.022443662846205935\nEpoch: 4, Train Loss: 0.020913395857482794\nEpoch: 5, Train Loss: 0.019961652491349794\nEpoch: 6, Train Loss: 0.018959988898852663\nEpoch: 7, Train Loss: 0.01798465642442655\nEpoch: 8, Train Loss: 0.01706515481289465\nEpoch: 9, Train Loss: 0.01628724265534185\nEpoch: 10, Train Loss: 0.015670407589388473\nEpoch: 11, Train Loss: 0.01507632825764068\nEpoch: 12, Train Loss: 0.014495246197212899\nEpoch: 13, Train Loss: 0.013965190483671277\nEpoch: 14, Train Loss: 0.013520454526470055\nEpoch: 15, Train Loss: 0.01313481977006545\nEpoch: 16, Train Loss: 0.012749494020118575\nEpoch: 17, Train Loss: 0.012383833343978516\nEpoch: 18, Train Loss: 0.011962811265108203\nEpoch: 19, Train Loss: 0.01165948455879559\nEpoch: 20, Train Loss: 0.011348466620196458\nEpoch: 21, Train Loss: 0.011035453853980925\nEpoch: 22, Train Loss: 0.010746113926278278\nEpoch: 23, Train Loss: 0.010498305341300564\nEpoch: 24, Train Loss: 0.010275044338054613\nEpoch: 25, Train Loss: 0.010022295522856092\nEpoch: 26, Train Loss: 0.009809599983748285\nEpoch: 27, Train Loss: 0.009599535422706444\nEpoch: 28, Train Loss: 0.009388710193904574\nEpoch: 29, Train Loss: 0.009202404613472373\nEpoch: 30, Train Loss: 0.008976058648619247\nEpoch: 31, Train Loss: 0.008813762477482322\nEpoch: 32, Train Loss: 0.008660790675643772\nEpoch: 33, Train Loss: 0.008470682796378675\nEpoch: 34, Train Loss: 0.008340694710930708\nEpoch: 35, Train Loss: 0.008177909771139866\nEpoch: 36, Train Loss: 0.008033203503989991\nEpoch: 37, Train Loss: 0.00789488595514188\nEpoch: 38, Train Loss: 0.007779954616449859\nEpoch: 39, Train Loss: 0.007628981825656367\nEpoch: 40, Train Loss: 0.007528121745168998\nEpoch: 41, Train Loss: 0.007409467907625315\nEpoch: 42, Train Loss: 0.00730723766774986\nEpoch: 43, Train Loss: 0.0071865046593050114\nEpoch: 44, Train Loss: 0.007079367623110513\nEpoch: 45, Train Loss: 0.0069976606991962766\nEpoch: 46, Train Loss: 0.006908085135400064\nEpoch: 47, Train Loss: 0.006810376064696205\nEpoch: 48, Train Loss: 0.0067309177939078\nEpoch: 49, Train Loss: 0.006644119537980562\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model Validation\n\nval_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\n# Switch to evaluation Mode\nmodel.eval()\n# Loop  through the Validation Set\nfor data, target in val_loader:\n    #Forward Pass\n    output = model(data)\n    # Calculate Loss\n    loss = criterion(output, target)\n    # Update the Validation Loss\n    val_loss += loss.item()*data.size(0)\n    # Convert Output probabilities to predicted Class\n    _, pred = torch.max(output, 1)\n    # Compare predictions to true label\n    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n    # Calculate Validation Accuracy for each object class\n    for i in range(len(target)):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n        \n# Calculate and Print Average Validation Loss\nval_loss = val_loss/len(val_loader.sampler)\nprint('Validation Loss: {:.6f}\\n'.format(val_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print(\"Validation Accuracy of %5s: %2d%% (%2d/%2d)\" %(str(i), 100 * class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])))\n        \n    else:\n        print(\"Validation Accuracy of %5s: N/A (no training examples)\" % (classes[i]))\n    \nprint(\"\\nValidation Accuracy (Overall): %2d%% (%2d/%2d)\" %(100 * np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)))","execution_count":24,"outputs":[{"output_type":"stream","text":"Validation Loss: 0.248454\n\nValidation Accuracy of     0: 98% (809/821)\nValidation Accuracy of     1: 98% (904/915)\nValidation Accuracy of     2: 96% (782/811)\nValidation Accuracy of     3: 96% (835/861)\nValidation Accuracy of     4: 97% (793/814)\nValidation Accuracy of     5: 96% (773/799)\nValidation Accuracy of     6: 98% (820/836)\nValidation Accuracy of     7: 96% (864/891)\nValidation Accuracy of     8: 95% (792/832)\nValidation Accuracy of     9: 96% (790/820)\n\nValidation Accuracy (Overall): 97% (8162/8400)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict for the Test Dataset\n\n# Switch to Evaluation Mode\nmodel.eval()\npredictions = []\n\nfor data in test_loader:\n    # Forward Pass\n    output = model(data[0])\n    # Calculate the Loss\n    _, pred = torch.max(output, 1)\n    predictions.extend(pred.tolist())","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub['Label'] = predictions\nsample_sub.to_csv('Sub_file2.csv', index=False)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}